# ğŸš— Lane & Road Segmentation using FCN-8 (VGG-16 Encoder)

This project implements **lane/road segmentation** using a **Fully Convolutional Network (FCN-8)** built on top of a **VGG-16 encoder**.  
The model is trained on the **KITTI Road Segmentation Dataset** and produces pixel-wise binary masks identifying drivable road areas.

## ğŸ“· Example Prediction 

```markdown
![Lane Segmentation Example 1](outputs/0.png)
![Lane Segmentation Example 2](outputs/1.png)
![Lane Segmentation Example 3](outputs/2.png)
---

## ğŸ“Œ Project Overview

Semantic segmentation identifies **which pixels belong to the road**.  
This project uses:

- **VGG-16** (pretrained on ImageNet) as the encoder  
- **FCN-8 decoder** with **skip connections**  
- **Concatenate-based fusion** to combine multi-scale features  
- **Bilinear upsampling** instead of transposed convolutions  
- **Binary cross-entropy loss**, **Mean IoU** metric  
- Full train â†’ validation â†’ test pipelines in TensorFlow

---

## ğŸ—‚ Dataset

KITTI Road Dataset (image + mask pairs)  
- Images resized to **128Ã—128** for stable downsampling  
- Masks converted to binary:  
  - **1 = road**  
  - **0 = non-road**

> ğŸ“Œ As shown in the dataset section , preprocessing includes resizing, normalization, and optional flips.

---

## ğŸ§  Why 128Ã—128 Input Size?

As explained in the notebook  VGG-16 downsamples the image **five times** using MaxPooling2D (Ã·2 each time): 128 â†’ 64 â†’ 32 â†’ 16 â†’ 8 â†’ 4

All values remain whole numbers â†’ crucial for clean upsampling in a decoder.

---

## ğŸ§± Model Architecture

### **1. Encoder â€“ Pretrained VGG-16**

We extract three feature maps:

| Encoder Layer        | Scale       | Purpose |
|----------------------|-------------|---------|
| `block5_pool`        | 1/32        | High-level semantics |
| `block4_pool`        | 1/16        | Mid-level structure |
| `block3_pool`        | 1/8         | Boundary details |



---

## ğŸ”„ Decoder Approach: Upsampling + Concatenate (FCN-8)

The decoder progressively reconstructs the segmentation mask using three stages:

### **Why Concatenate? (Final Choice)**

 **Concatenate Technqie was finally selected** because it yeilded the best results and:

1. **Preserves full feature information**  
   Skip features are not added or averaged â€” they are fully retained.

2. **Improves boundary accuracy**  
   Especially important for lane edges.

3. **More flexible than Add()**  
   `Add` requires identical channels; `Concatenate` does not.

4. **Matches the FCN-8 design**  
   FCN-8 combines multi-scale features from  
   `block5 â†’ block4 â†’ block3`.

5. **Reduces over-smoothing**  
   Better gradient flow from early layers.


---

## ğŸ—ï¸ FCN-8 Decoder Structure
Upsampling uses **bilinear interpolation** (smooth, checkerboard-free).

---

## ğŸ§ª Training Setup

- **Loss:** `BinaryCrossentropy`
- **Optimizer:** `Adam()`
- **Metric:** `MeanIoU`
- **Callbacks:**  
  - TensorBoard  
  - Early Stopping  
  - ModelCheckpoint  
  - Live prediction display callback

---

## ğŸ“¦ Data Pipeline

### Training Pipeline  
- Resize â†’ 128Ã—128  
- Random horizontal flip  
- Normalize image  
- Shuffle â†’ Batch (32) â†’ Repeat â†’ Prefetch

### Validation Pipeline  
- Resize + Normalize  
- No augmentation  
- Deterministic

### Test Pipeline  
- Single pass, no augmentation  
- Batch + prefetch

---

## ğŸ“Š Prediction & Visualization

Two visualization modes:

### **1. Image-wise Output**
Shows:
- Input image  
- Predicted mask overlay (pink)  

### **2. Video Output**
On each frame:
- Resize  
- Predict mask  
- Weighted overlay  
- Write to output video  




